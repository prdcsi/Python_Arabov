import os
import re
import chardet
from collections import Counter

def detect_encoding(file_path):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞."""
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        result = chardet.detect(raw_data)
        encoding = result['encoding']
        if encoding is None:
            encoding = 'utf-8'  # fallback
        return encoding

def read_text_file(file_path):
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏."""
    encoding = detect_encoding(file_path)
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            return f.read()
    except UnicodeDecodeError:
        # –ï—Å–ª–∏ chardet –æ—à–∏–±—Å—è, –ø—Ä–æ–±—É–µ–º utf-8 –∏ latin-1 –∫–∞–∫ fallback
        for enc in ['utf-8', 'latin-1']:
            try:
                with open(file_path, 'r', encoding=enc) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏.")

def analyze_text(text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏."""
    # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤
    total_chars_with_spaces = len(text)
    total_chars_without_spaces = len(text.replace(' ', '').replace('\n', '').replace('\t', ''))

    # –°–ª–æ–≤–∞: —Ç–æ–ª—å–∫–æ –±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    words = re.findall(r'\b\w+\b', text.lower())
    total_words = len(words)
    unique_words = set(words)
    num_unique_words = len(unique_words)

    # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'[.!?]+', text)
    # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ split
    sentences = [s.strip() for s in sentences if s.strip()]
    total_sentences = len(sentences)

    # –¢–æ–ø-10 —Å–ª–æ–≤
    word_counts = Counter(words)
    top_10_words = word_counts.most_common(10)

    return {
        'total_words': total_words,
        'total_chars_with_spaces': total_chars_with_spaces,
        'total_chars_without_spaces': total_chars_without_spaces,
        'total_sentences': total_sentences,
        'unique_words_count': num_unique_words,
        'top_10_words': top_10_words
    }

def generate_report(analysis, original_file):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç."""
    report = []
    report.append("üìÑ –û—Ç—á—ë—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–∫—Å—Ç–∞")
    report.append("=" * 40)
    report.append(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {os.path.basename(original_file)}")
    report.append("")
    report.append(f"üîπ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {analysis['total_words']}")
    report.append(f"üîπ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ (—Å –ø—Ä–æ–±–µ–ª–∞–º–∏): {analysis['total_chars_with_spaces']}")
    report.append(f"üîπ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤): {analysis['total_chars_without_spaces']}")
    report.append(f"üîπ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {analysis['total_sentences']}")
    report.append(f"üîπ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {analysis['unique_words_count']}")
    report.append("")
    report.append("üî• –¢–æ–ø-10 —Å–∞–º—ã—Ö —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è —Å–ª–æ–≤:")
    for i, (word, count) in enumerate(analysis['top_10_words'], 1):
        report.append(f"  {i}. '{word}' ‚Äî {count} —Ä–∞–∑(–∞)")
    report.append("")
    report.append("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–æ–π ¬´–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞¬ª.")
    return "\n".join(report)

def save_report(report_text, original_file):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á—ë—Ç –≤ —Ñ–∞–π–ª —Å –∏–º–µ–Ω–µ–º report_<original>.txt"""
    base_name = os.path.splitext(os.path.basename(original_file))[0]
    report_file = f"report_{base_name}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_text)
    return report_file

def main():
    print("üîç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞")
    print("-" * 30)
    file_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É: ").strip()

    if not os.path.isfile(file_path):
        print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É.")
        return

    try:
        print("‚è≥ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏...")
        text = read_text_file(file_path)

        print("üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞...")
        analysis = analyze_text(text)

        print("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞...")
        report = generate_report(analysis, file_path)

        report_file = save_report(report, file_path)
        print(f"‚úÖ –û—Ç—á—ë—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ —Ñ–∞–π–ª: {report_file}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")

if __name__ == "__main__":
    main()